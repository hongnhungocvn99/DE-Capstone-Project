{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "In this project, I will use I94 immigration, global land temperatures and US demographics datasets to design a data warehouse schema with an ETL pipeline.\n",
    "\n",
    "There are 5 steps in this project\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\") \\\n",
    "    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### 1.1 Scope \n",
    "\n",
    "##### 1.1.1 Data format\n",
    "I use the data provided which in formats SAS or CSV.\n",
    "\n",
    "##### 1.1.2 Technology used\n",
    "Language in this project: Python  \n",
    "Processing on datasets: PySpark  \n",
    "Vizualize data: Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2 Dataset description\n",
    "\n",
    "| Dataset                                                                                                       | Format | Description|\n",
    "|:---------------------------------------------------------------------------------------------------------------|:--------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| [I94 Immigration Data](https://www.trade.gov/national-travel-and-tourism-office)                              | SAS    | This data comes from the US National Tourism and Trade Office. This dataset contains immigration data of individuals coming to USA in the year 2016. A data dictionary is included in the workspace. immigration_data_sample.csv contains the sample data.|\n",
    "| [World Temperature Data](https://public.opendatasoft.com/explore/dataset/us-cities-demographic/information/) | CSV    | This dataset came from Kaggle. This dataset contains information of temperatures by city for each country.|\n",
    "| [U.S. City demographic Data](https://public.opendatasoft.com/explore/dataset/us-cities-demographic/export/)  | CSV    | This data comes from OpenSoft. This dataset contains information about the demographic of all US cities and census-designated places with a population greater or equal to 65,000. This data comes from the US Census Bureau's 2015 American Community Survey.|\n",
    "| [Airport Code Data](https://datahub.io/core/airport-codes#data)                                              | CSV    | This data comes from Our Airports. It is a simple table of airport codes and corresponding cities. It contains the list of all airport codes, the attributes are identified in datapackage description. Some of the columns contain attributes identifying airport locations, other codes (IATA, local if exist) that are relevant to identification of an airport.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.2.1. I94 Immigration Data Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In Immigtation datasets,June data has difference columns from other month so i will read the June data and process it separately before joining with the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get file path\n",
    "all_file_list = [\n",
    " '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_sep16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_nov16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_mar16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_aug16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_may16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_oct16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_jul16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_feb16_sub.sas7bdat',\n",
    " '../../data/18-83510-I94-Data-2016/i94_dec16_sub.sas7bdat']\n",
    "\n",
    "june_file_path = '../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read immigration_df not include June\n",
    "nonjune_immigration_df = spark.read.format(\"com.github.saurfang.sas.spark\").load(all_file_list.pop())\n",
    "for file in all_file_list:\n",
    "    nonjune_immigration_df = nonjune_immigration_df.union(spark.read.format(\"com.github.saurfang.sas.spark\").load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read June immigration_df\n",
    "june_immigration_df = spark.read.format(\"com.github.saurfang.sas.spark\").load(june_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join immigration_df\n",
    "immigration_df = nonjune_immigration_df.union(june_immigration_df.select(*nonjune_immigration_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20789.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20802.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>05262018</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>RS</td>\n",
       "      <td>9.755414e+10</td>\n",
       "      <td>7715</td>\n",
       "      <td>E2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>20789.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OH</td>\n",
       "      <td>20835.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>CA</td>\n",
       "      <td>9.062372e+10</td>\n",
       "      <td>819</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>PEV</td>\n",
       "      <td>20789.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>20794.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>06012017</td>\n",
       "      <td>M</td>\n",
       "      <td>5920</td>\n",
       "      <td>None</td>\n",
       "      <td>8.010503e+10</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>PEV</td>\n",
       "      <td>20789.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20792.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>06012017</td>\n",
       "      <td>F</td>\n",
       "      <td>5920</td>\n",
       "      <td>None</td>\n",
       "      <td>8.010511e+10</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>PEV</td>\n",
       "      <td>20789.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20792.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>06012017</td>\n",
       "      <td>M</td>\n",
       "      <td>5920</td>\n",
       "      <td>None</td>\n",
       "      <td>8.010511e+10</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0   46.0  2016.0    12.0   129.0   129.0     HOU  20789.0      1.0      TX   \n",
       "1   56.0  2016.0    12.0   245.0   245.0     NEW  20789.0      1.0      OH   \n",
       "2   67.0  2016.0    12.0   512.0   512.0     PEV  20789.0      2.0      MD   \n",
       "3   68.0  2016.0    12.0   512.0   512.0     PEV  20789.0      2.0      FL   \n",
       "4   69.0  2016.0    12.0   512.0   512.0     PEV  20789.0      2.0      HI   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0  20802.0   ...        None        M   1970.0  05262018      M   None   \n",
       "1  20835.0   ...        None        M   1988.0       D/S      F   None   \n",
       "2  20794.0   ...        None        M   1968.0  06012017      M   5920   \n",
       "3  20792.0   ...        None        M   1970.0  06012017      F   5920   \n",
       "4  20792.0   ...        None        M   1968.0  06012017      M   5920   \n",
       "\n",
       "  airline        admnum fltno visatype  \n",
       "0      RS  9.755414e+10  7715       E2  \n",
       "1      CA  9.062372e+10   819       F1  \n",
       "2    None  8.010503e+10  None       B2  \n",
       "3    None  8.010511e+10  None       B2  \n",
       "4    None  8.010511e+10  None       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 record of dataset\n",
    "immigration_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of dataset\n",
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.2.2. World Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = spark.read.csv(fname, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 record of dataset\n",
    "temperature_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of dataset\n",
    "temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.2.3. U.S. City demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = \"us-cities-demographics.csv\"\n",
    "demographic_df = spark.read.csv(fname, inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 record of dataset\n",
    "demographic_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of dataset\n",
    "demographic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.2.4. Airport Code Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = \"airport-codes_csv.csv\"\n",
    "airport_df = spark.read.csv(fname, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport            11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          3435   \n",
       "2  00AK  small_airport                        Lowell Field           450   \n",
       "3  00AL  small_airport                        Epps Airpark           820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport           237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 record of dataset\n",
    "airport_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of dataset\n",
    "airport_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Explore the Data  \n",
    "All schema of data has been printed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Some more information is in the file I94_SAS_Labels_Descriptions.SAS. So I will process it to get the following information\n",
    "- Port code\n",
    "- Visa type\n",
    "- Country code\n",
    "- State code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read I94 Immigration description file\n",
    "with open(\"I94_SAS_Labels_Descriptions.SAS\") as raw_data:\n",
    "    lines = raw_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract port data\n",
    "raw_port_data = lines[302:961]\n",
    "port_ls = []\n",
    "\n",
    "for line in raw_port_data:\n",
    "    temp = line.split(\"=\")\n",
    "    data = [temp[0].strip().strip(\"'\"),\n",
    "            temp[1].strip().strip(\"'\").split(\",\")[0]]\n",
    "    port_ls.append(data)\n",
    "\n",
    "port_df = spark.createDataFrame(pd.DataFrame(port_ls, columns=[\"port_cd\", \"port_city\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract country data\n",
    "raw_country_data = lines[9:298]\n",
    "country_ls = []\n",
    "\n",
    "for line in raw_country_data:\n",
    "    temp = line.split(\"=\")\n",
    "    data = [temp[0].strip(), temp[1].strip().strip(\"'\").strip(\";\")]\n",
    "    country_ls.append(data)\n",
    "\n",
    "country_df = spark.createDataFrame(\n",
    "    pd.DataFrame(country_ls, columns=[\"country_cd\", \"country_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract visa data\n",
    "raw_visa_data = lines[1046:1049]\n",
    "visa_ls = []\n",
    "\n",
    "for line in raw_visa_data:\n",
    "    temp = line.split(\"=\")\n",
    "    data = [temp[0].strip(), temp[1].strip().strip(\"'\").strip(\";\")]\n",
    "    visa_ls.append(data)\n",
    "\n",
    "visa_df = spark.createDataFrame(pd.DataFrame(visa_ls, columns=[\"visa_cd\", \"visa_type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract state data\n",
    "raw_state_data = lines[981:1036]\n",
    "state_ls = []\n",
    "\n",
    "for line in raw_state_data:\n",
    "    temp = line.split(\"=\")\n",
    "    data = [temp[0].strip().strip(\"'\"), temp[1].strip().strip(\"'\").strip(\";\")]\n",
    "    state_ls.append(data)\n",
    "\n",
    "state_df = spark.createDataFrame(pd.DataFrame(state_ls, columns=[\"state_cd\", \"state_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1 I94 Immigration Data\n",
    "- I only use which have arrdate and \"i94mode == 1\".\n",
    "- Convert some column from string into integer.\n",
    "- Convert arrive/depart date to yyyy-mm-dd format.\n",
    "- Rename some columns into friendly names for coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean I94 Immigration Data\n",
    "proc_immigration_df = immigration_df \\\n",
    "    .filter((col(\"arrdate\").isNotNull()) & (col(\"i94mode\") == 1)) \\\n",
    "    .withColumn(\"arrived_date\", f.expr(\"date_add('1960-01-01', arrdate)\")) \\\n",
    "    .withColumn(\"departed_date\", f.expr(\"date_add('1960-01-01', depdate)\")) \\\n",
    "    .select(\n",
    "        col(\"cicid\").cast(IntegerType()).alias(\"cicid\"),\n",
    "        col(\"i94yr\").cast(IntegerType()).alias(\"year\"),\n",
    "        col(\"i94mon\").cast(IntegerType()).alias(\"month\"),\n",
    "        col(\"i94res\").cast(IntegerType()).alias(\"departed_cd\"),\n",
    "        col(\"i94port\").alias(\"arrived_cd\"),\n",
    "        col(\"i94addr\").alias(\"state_cd\"),\n",
    "        col(\"arrived_date\"),\n",
    "        col(\"departed_date\"),\n",
    "        col(\"i94visa\").alias(\"visa_cd\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.2 World Temperature Data\n",
    "- Only use data which have \"Country == United States\" and years from 2006~2016\n",
    "- Rename some columns into friendly names for coding.\n",
    "- Convert some column from string into integer/float.\n",
    "- Drop record which doesn't have temperature.\n",
    "- Drop duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cleaning World Temperature Data\n",
    "proc_temperature_df = temperature_df\\\n",
    "    .filter(\n",
    "        (col(\"Country\") == \"United States\")\n",
    "        & (col(\"dt\") >= \"2006-01-01\")\n",
    "        & (col(\"dt\") <= \"2016-12-31\")\n",
    "    )\\\n",
    "    .select(\n",
    "        to_date(col(\"dt\")).alias(\"date\"),\n",
    "        col(\"AverageTemperature\").cast(FloatType()).alias(\"avg_temp\"),\n",
    "        col(\"City\").alias(\"city\"),\n",
    "        col(\"Country\").alias(\"country_name\"),\n",
    "        split(col(\"Latitude\"), \"N\")\n",
    "            .getItem(0).cast(FloatType()).alias(\"latitude\"),\n",
    "        split(col(\"Longitude\"), \"W\")\n",
    "            .getItem(0).cast(FloatType()).alias(\"longitude\")) \\\n",
    "    .withColumn(\"longitude\",col(\"longitude\") * -1) \\\n",
    "    .dropDuplicates([\"date\",\"city\"])\\\n",
    "    .filter(col(\"avg_temp\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.3 U.S. City demographic Data\n",
    "- Convert some column from string into integer/float.\n",
    "- Rename some columns into friendly names for coding.\n",
    "- Fill missing values from Male Population, Female Population, Total Population, Number of Veterans, Foreign-born with 0.\n",
    "- Drop duplicated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ===========U.S. City demographic Data=========== #\n",
    "demographic_COLS = [\"city\", \"state\", \"median_age\",\n",
    "                    \"male_population\", \"female_population\", \"total_population\",\n",
    "                    \"num_veterans\", \"foreign_born\", \"avg_household_size\",\n",
    "                    \"state_code\", \"race\", \"count\"]\n",
    "\n",
    "# Rename columns and convert type\n",
    "proc_demographic_df = demographic_df.toDF(*demographic_COLS)\n",
    "proc_demographic_df = proc_demographic_df.select(\n",
    "    col(\"city\"),\n",
    "    col(\"state\").alias(\"state_name\"),\n",
    "    col(\"median_age\").cast(FloatType()),\n",
    "    col(\"male_population\").cast(IntegerType()),\n",
    "    col(\"female_population\").cast(IntegerType()),\n",
    "    col(\"total_population\").cast(IntegerType()),\n",
    "    col(\"num_veterans\").cast(IntegerType()),\n",
    "    col(\"foreign_born\").cast(IntegerType()),\n",
    "    col(\"avg_household_size\").cast(FloatType()),\n",
    "    col(\"state_code\").alias(\"state_cd\"),\n",
    "    col(\"race\")\n",
    ")\n",
    "# Fill missing values from Male Population, Female Population, Total Population,\n",
    "# Number of Veterans, Foreign-born\n",
    "proc_demographic_df = proc_demographic_df.na.fill({\n",
    "    \"male_population\": 0,\n",
    "    \"female_population\": 0,\n",
    "    \"total_population\": 0,\n",
    "    \"num_veterans\": 0,\n",
    "    \"foreign_born\": 0,\n",
    "})\n",
    "\n",
    "# Filter out duplicated data\n",
    "proc_demographic_df = proc_demographic_df.dropDuplicates([\"state_cd\",\"city\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.4 Airport Code Data\n",
    "- Only use data which have \"iso_country == US\"\n",
    "- Only use airport data (%airport)\n",
    "- Split coordinates into latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cleaning Airport Code Data\n",
    "proc_airport_df = airport_df\\\n",
    "    .filter(\n",
    "        (col(\"iso_country\") == \"US\")\n",
    "        & (col(\"type\").like(\"%airport\"))\n",
    "    )\\\n",
    "    .withColumn(\"longitude\", split(col(\"coordinates\"), \",\")\n",
    "                .getItem(0).cast(FloatType())) \\\n",
    "    .withColumn(\"latitude\", split(col(\"coordinates\"), \",\")\n",
    "                .getItem(1).cast(FloatType())) \\\n",
    "    .select(\n",
    "        col(\"ident\").alias(\"id\"),\n",
    "        col(\"name\"),\n",
    "        col(\"type\"),\n",
    "        col(\"elevation_ft\").alias(\"elevation\"),\n",
    "        split(col(\"iso_region\"),\"-\").getItem(1).alias(\"state_cd\"),\n",
    "        col(\"latitude\"),\n",
    "        col(\"longitude\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "I choose star model due to its simplicity in querying other informations with the needs of complex joins.  \n",
    "![Fig 1. Database schema](./images/diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "##### 3.2.1 state_temperature as a dimension table\n",
    "I will join World Temperature Data with U.S. City demographic Data to calculate min/average/max temperature of each state by month and year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.2.2 state_demographic as a dimension table\n",
    "I will aggregate informations by state and race from U.S. City demographic Data and add \"sex_ratio\" column with below formula:\n",
    "```\n",
    "sex_ratio = male_population / female_population * 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.2.3 state_airport as a dimension table\n",
    "From the Airport Code Data I will combine with the data from I94_SAS_Labels_Descriptions.SAS to get the \"state_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.2.4 immigration as a fact table\n",
    "From the Immigration Data I will combine with the data from I94_SAS_Labels_Descriptions.SAS to get the \"port\", \"country\", \"state\", \"visa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n",
    "##### 4.1.1 Construct state_temperature as a dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create state_temperature data\n",
    "state_temperature_df = proc_temperature_df\\\n",
    "    .withColumn(\"month\", month(\"date\"))\\\n",
    "    .withColumn(\"year\", year(\"date\"))\\\n",
    "    .join(proc_demographic_df, \"city\")\\\n",
    "    .groupby([\"month\", \"year\", \"state_cd\", \"state_name\"])\\\n",
    "    .agg(\n",
    "        avg(\"avg_temp\").cast(FloatType()).alias(\"avg_temp\"),\n",
    "        max(\"avg_temp\").alias(\"max_temp\"),\n",
    "        min(\"avg_temp\").alias(\"min_temp\")\n",
    "    )\\\n",
    "    .select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- state_cd: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- avg_temp: float (nullable = true)\n",
      " |-- max_temp: float (nullable = true)\n",
      " |-- min_temp: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.2 Construct state_demographic as a dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create state_demographic data\n",
    "state_demographic_df = proc_demographic_df\\\n",
    "    .groupby([\"state_cd\", \"state_name\", \"race\"])\\\n",
    "    .agg(\n",
    "        round(avg(\"median_age\"), 2).cast(FloatType()).alias(\"median_age\"),\n",
    "        sum(\"male_population\").alias(\"male_population\"),\n",
    "        sum(\"female_population\").alias(\"female_population\"),\n",
    "        sum(\"total_population\").alias(\"total_population\"),\n",
    "        sum(\"num_veterans\").alias(\"num_veterans\"),\n",
    "        sum(\"foreign_born\").alias(\"foreign_born\"),\n",
    "        round(avg(\"avg_household_size\"),2).cast(FloatType()).alias(\"avg_household_size\")\n",
    "    )\\\n",
    "    .withColumn(\"sex_ratio\",\n",
    "                round(col(\"male_population\")/col(\"female_population\")*100, 2).cast(FloatType()))\\\n",
    "    .select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_cd: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- male_population: long (nullable = true)\n",
      " |-- female_population: long (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- num_veterans: long (nullable = true)\n",
      " |-- foreign_born: long (nullable = true)\n",
      " |-- avg_household_size: float (nullable = true)\n",
      " |-- sex_ratio: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_demographic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.3 Construct state_airport as a dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create state_airport data\n",
    "state_airport_df = proc_airport_df.alias(\"proc_airport_df\")\\\n",
    "    .join(state_df.alias(\"state_df\"),\n",
    "          col(\"proc_airport_df.state_cd\") == col(\"state_df.state_cd\"))\\\n",
    "    .select(\n",
    "        col(\"proc_airport_df.id\"),\n",
    "        col(\"proc_airport_df.name\").alias(\"airport_name\"),\n",
    "        col(\"proc_airport_df.state_cd\"),\n",
    "        col(\"state_df.state_name\"),\n",
    "        col(\"proc_airport_df.type\"),\n",
    "        col(\"proc_airport_df.elevation\"),\n",
    "        col(\"proc_airport_df.latitude\"),\n",
    "        col(\"proc_airport_df.longitude\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- state_cd: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- elevation: integer (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_airport_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.1.4 Construct immigration as a fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create immigration data\n",
    "immigration_df = proc_immigration_df.alias(\"org_data\")\\\n",
    "    .join(port_df.alias(\"port\"),\n",
    "          col(\"org_data.arrived_cd\") == col(\"port.port_cd\"))\\\n",
    "    .join(country_df.alias(\"country\"),\n",
    "          col(\"org_data.departed_cd\") == col(\"country.country_cd\"))\\\n",
    "    .join(state_df.alias(\"state\"),\n",
    "          col(\"org_data.state_cd\") == col(\"state.state_cd\"))\\\n",
    "    .join(visa_df.alias(\"visa\"),\n",
    "          col(\"org_data.visa_cd\") == col(\"visa.visa_cd\"))\\\n",
    "    .select(\"*\")\\\n",
    "    .filter(col(\"state_name\").isNotNull())\\\n",
    "    .select(\n",
    "        col(\"org_data.cicid\"),\n",
    "        col(\"org_data.month\"),\n",
    "        col(\"org_data.year\"),\n",
    "        col(\"org_data.state_cd\"),\n",
    "        col(\"state.state_name\"),\n",
    "        col(\"org_data.departed_date\"),\n",
    "        col(\"org_data.departed_cd\"),\n",
    "        col(\"country.country_name\").alias(\"departed_country\"),\n",
    "        col(\"org_data.arrived_date\"),\n",
    "        col(\"org_data.arrived_cd\"),\n",
    "        col(\"port.port_city\").alias(\"arrived_port\"),\n",
    "        col(\"visa.visa_type\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- state_cd: string (nullable = true)\n",
      " |-- state_name: string (nullable = true)\n",
      " |-- departed_date: date (nullable = true)\n",
      " |-- departed_cd: integer (nullable = true)\n",
      " |-- departed_country: string (nullable = true)\n",
      " |-- arrived_date: date (nullable = true)\n",
      " |-- arrived_cd: string (nullable = true)\n",
      " |-- arrived_port: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.1 Verify state_temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 3905\n"
     ]
    }
   ],
   "source": [
    "# Count total records of table\n",
    "print(\"Total records: {}\".format(state_temperature_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>state_cd</th>\n",
       "      <th>state_name</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  year  state_cd  state_name  avg_temp  max_temp  min_temp\n",
       "0      0     0         0           0         0         0         0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count invalid (NaN, NULL) value of target columns (\"state_temperature_df.columns\")\n",
    "state_temperature_df.select(\n",
    "    [count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in state_temperature_df.columns]\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.2 Verify state_airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 14575\n"
     ]
    }
   ],
   "source": [
    "# Count total records of table\n",
    "print(\"Total records: {}\".format(state_airport_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  state_cd\n",
       "0   0         0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count NULL value of target columns (state_airport_df.id, state_airport_df.state_cd)\n",
    "lst_columns = [\"id\", \"state_cd\"]\n",
    "state_airport_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in lst_columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.3 Verify state_demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 174\n"
     ]
    }
   ],
   "source": [
    "# Count total records of table\n",
    "print(\"Total records: {}\".format(state_demographic_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>state_cd</th>\n",
       "      <th>sex_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race  state_cd  sex_ratio\n",
       "0     0         0          0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count invalid (NaN, NULL) value of target columns (state_demographic_df.race, state_demographic_df.state_cd, state_demographic_df.sex_ratio)\n",
    "lst_columns = [\"race\", \"state_cd\", \"sex_ratio\"]\n",
    "state_demographic_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in lst_columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.4 Verify immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 37227531\n"
     ]
    }
   ],
   "source": [
    "# Count total records of table\n",
    "print(\"Total records: {}\".format(immigration_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>departed_date</th>\n",
       "      <th>departed_cd</th>\n",
       "      <th>arrived_date</th>\n",
       "      <th>arrived_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2798756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  month  year  departed_date  departed_cd  arrived_date  arrived_cd\n",
       "0      0      0     0        2798756            0             0           0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count NULL value of target columns\n",
    "lst_columns = [\"cicid\", \"month\", \"year\",\"departed_date\", \"departed_cd\",\"arrived_date\", \"arrived_cd\"]\n",
    "immigration_df.select([count(when(col(c).isNull(), c)).alias(c) for c in lst_columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.1 Tools and technologies\n",
    "\n",
    "In this project, I use Spark for ETL processes due to below reasons:\n",
    "- Ability to read multiple data formats (json, avro, parquet etc.)\n",
    "- Spark is distributed data processing engine, which will enable scaling when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.2 Update frequency\n",
    "- immigration data should be updated daily, only appending new records into fact table. \n",
    "- state_temperature data only needs to be updated monthly because temperature data's fluctuation is not so impactful.\n",
    "- state_demographic and state_airport are long-term related data. I think we should update these table monthly or quarterly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3 Resolving scenarios\n",
    "###### 5.3.1 The data was increased by 100x\n",
    "To resolve that we can use cloud storage services (AWS S3, Google Cloud Storage,...).\n",
    "Then we can use AWS EMR to build data pipelines with reasonable cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### 5.3.2 The data populates a dashboard that must be updated on a daily basis by 7am every day\n",
    "Use Apache Airflow to build data pipelines at scheduled inverals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### 5.3.3 The database needed to be accessed by 100+ people\n",
    "AWS Redshift can support 100+ people with access. Use it to solve this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
